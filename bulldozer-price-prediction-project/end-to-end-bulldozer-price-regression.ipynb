{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Predicting the Sale Price of Bulldozers using Machine Learning\n",
    "\n",
    "In this notebook, we're going to go through an example machine learning project with the goal of predicting the sale price of bulldozers \n",
    "\n",
    "## 1. Problem Definition \n",
    "\n",
    "> How well can we predict the future sale price of a bulldozer, give it's characteristics and previous examples of how much similar bulldozers have been sold for?\n",
    "\n",
    "## 2. Data\n",
    "The data is downloaded from the Kaggle Bluebook for bulldozers competition: https://www.kaggle.com/competitions/bluebook-for-bulldozers/data\n",
    "\n",
    "The data for this competition is split into three parts:\n",
    "\n",
    "* Train.csv is the training set, which contains data through the end of 2011.\n",
    "* Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n",
    "* Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.\n",
    "\n",
    "\n",
    "## 3. Evaluation \n",
    "\n",
    "The evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n",
    "\n",
    "For more on the evaluation of this project check: https://www.kaggle.com/competitions/bluebook-for-bulldozers/overview\n",
    "\n",
    "**Note**: The goal for most regression evaluation metrics is to minimize the error. For example, our goal for this project will be to build a machine learning model which minimises RSMLE.\n",
    "\n",
    "\n",
    "## 4.Features\n",
    "\n",
    "Kaggle provides a data dictionary: https://www.kaggle.com/competitions/bluebook-for-bulldozers/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data training & validation\n",
    "\n",
    "df = pd.read_csv(\"./data/TrainAndValid.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"SalePrice\"].hist()  # taking too long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Parsing Dates \n",
    "\n",
    "When we work with time series data, we want to enrich the time & date component as much as possible. \n",
    "\n",
    "We can do that by telling pandas which of our columns has dates in it using the `parse_dates` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data again but this time parse dates \n",
    "df = pd.read_csv(\"./data/TrainAndValid.csv\", low_memory=False, parse_dates =[\"saledate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Sort DataFrame by saledate \n",
    "\n",
    "When working with Time Series Data it is a good idea to sort it by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"saledate\"], inplace = True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Make Copy of the original DataFrame \n",
    "\n",
    "We make a copy of the original dataframe so when we manipulate the copy, we have still got our original data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy \n",
    "df_temp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.saledate.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Add datetime parameters for `saledate` column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp[\"saleYear\"] = df_temp.saledate.dt.year\n",
    "df_temp[\"saleMonth\"] = df_temp.saledate.dt.month\n",
    "df_temp[\"saleDay\"] = df_temp.saledate.dt.day\n",
    "df_temp[\"saleDayOfWeek\"] = df_temp.saledate.dt.dayofweek\n",
    "df_temp[\"saleDayOfYear\"] = df_temp.saledate.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have enriched our DataFrame with date time features we can remove saledate \n",
    "df_temp.drop(\"saledate\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the values of diffrent columns \n",
    "df_temp.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 5. Modelling \n",
    "\n",
    "We've done enough EDA (we could always do more)  but let's start to do some model driven EDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_jobs=-1,\n",
    "                             random_state = 42 #same like random_seed\n",
    "                             )\n",
    "\n",
    "#model.fit(df_temp.drop(\"SalePrice\",axis = 1), df_temp.SalePrice) # is not working because we have some features which datatypes are object "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Convert string to categories \n",
    "\n",
    "One way we can turn all of our data into numbers is by converting them into panda categories \n",
    "\n",
    "We can check the opportunities here: https://pandas.pydata.org/docs/reference/api/pandas.Categorical.dtype.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_string_dtype(df_temp[\"UsageBand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the columns which contain strings\n",
    "for label, content in df_temp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are wondering what df.items does here is a example \n",
    "\n",
    "random_dict = {\"key1\":\"Hello\",\n",
    "               \"key2\":\"World\", }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in random_dict.items():\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will turn all of the string values into category values \n",
    "\n",
    "for label, content in df_temp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        df_temp[label] = content.astype(\"category\").cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir wandeln diese Spalte(n) in den pandas-Datentyp \"category\" um.\n",
    "# Dabei speichert pandas nicht jeden String-Wert pro Zeile, sondern:\n",
    "#   1) eine feste Liste aller möglichen Kategorien (Labels) und\n",
    "#   2) pro Zeile nur einen integer Code, der auf die Kategorie zeigt.\n",
    "# Vorteil: weniger Speicherverbrauch und oft schnellere Operationen bei wenigen, häufig wiederholten Werten.\n",
    "# Optional (falls gesetzt): Mit ordered=True bekommt die Kategorie eine feste Reihenfolge, die Sortierung/Vergleiche beeinflusst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.state.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will turn all of the object values into category values \n",
    "\n",
    "for label, content in df_temp.items():\n",
    "    if pd.api.types.is_object_dtype(content):\n",
    "        df_temp[label] = content.astype(\"category\").cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir wandeln diese Spalte(n) in den pandas-Datentyp \"category\" um.\n",
    "# Dabei speichert pandas nicht jeden String-Wert pro Zeile, sondern:\n",
    "#   1) eine feste Liste aller möglichen Kategorien (Labels) und\n",
    "#   2) pro Zeile nur einen integer Code, der auf die Kategorie zeigt.\n",
    "# Vorteil: weniger Speicherverbrauch und oft schnellere Operationen bei wenigen, häufig wiederholten Werten.\n",
    "# Optional (falls gesetzt): Mit ordered=True bekommt die Kategorie eine feste Reihenfolge, die Sortierung/Vergleiche beeinflusst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.state.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Thanks to pandas Categories we now have a way to access all of our data in the form of numbers.\n",
    "\n",
    "But we still have a bunch of missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.isnull().sum()/len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export current temp df \n",
    "\n",
    "df_temp.to_csv(\"data/train_temp.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed data \n",
    "\n",
    "df_temp=pd.read_csv(\"data/train_temp.csv\", low_memory= False)\n",
    "\n",
    "df_temp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.isnull().sum()/len(df_temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "## Fill missing values\n",
    "\n",
    "### Fill numerical missing values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label,content in df_temp.items(): \n",
    "    if pd.api.types.is_object_dtype(content): # if read_csv we need to change the dtype again to categorical\n",
    "        df_temp[label] = content.astype(\"category\").cat.as_ordered()\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        df_temp[label] = content.astype(\"category\").cat.as_ordered()\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)\n",
    "\n",
    "# Hinweis: CSV-Dateien speichern keine Datentyp-Informationen (nur Werte als Text).\n",
    "# Beim pd.read_csv() werden die Spaltentypen deshalb von pandas neu \"erraten\" (Type Inference),\n",
    "# wodurch z.B. category, datetime oder Strings mit führenden Nullen als andere dtypes eingelesen werden können.\n",
    "# Lösung: dtypes/parse_dates beim Import explizit setzen oder ein Format wie Parquet/Feather nutzen, das dtypes mit speichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.ModelID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for which numeric columns have null values \n",
    "\n",
    "for label,content in df_temp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numeric rows with the median \n",
    "\n",
    "for label,content in df_temp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            #Add a binary column which tells us if the data was missing \n",
    "            df_temp[label+\"_is_missing\"] = pd.isnull(content) \n",
    "            #Fill missing numeric values with median \n",
    "            df_temp[label]= content.fillna(content.median())\n",
    "\n",
    "# Mean (arithm. Mittelwert) = Summe aller Werte / Anzahl: nutzt jede Beobachtung direkt und wird durch Ausreißer stark beeinflusst.\n",
    "# Median = der mittlere Wert der sortierten Daten (bei gerader Anzahl: Mittel der zwei mittleren): robust gegenüber Ausreißern\n",
    "# und oft besser für schiefe Verteilungen (z.B. Einkommen, Preise, Wartezeiten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for which numeric columns have null values \n",
    "\n",
    "for label,content in df_temp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.auctioneerID_is_missing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filling and turning categorical variables into numbers \n",
    "\n",
    "\n",
    "#Check for columns which arent't numeric \n",
    "\n",
    "for label,content in df_temp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content): \n",
    "        print(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df_temp[\"state\"]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df_temp[\"state\"]).codes # if missing value then -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn categorical variables into number and fill missing \n",
    "\n",
    "for label,content in df_temp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content): \n",
    "        # add binary columns to indicate whether sample had missing value \n",
    "        df_temp[label+\"_is_missing\"] = pd.isnull(content)\n",
    "        #Turn categories into numbers and add +1 \n",
    "        df_temp[label] = pd.Categorical(content).codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.isna().sum()[:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    " Now that all of our data is numeric as well as our df has no missing values, we should be able to build a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "#JN Function to calculate how much time the cell take\n",
    "#Instantiate model\n",
    "model = RandomForestRegressor(n_jobs = -1)\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "model.fit(df_temp.drop(\"SalePrice\", axis = 1), df_temp[\"SalePrice\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model with train data wrong\n",
    "model.score(df_temp.drop(\"SalePrice\", axis = 1), df_temp[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "Why doesn't the above metric reliable? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### Splitting data into train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.saleYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.saleYear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Split We have data leakage because we calculate the median with past and future datasets\n",
    "df_val   = df_temp[df_temp.saleYear == 2012].copy()\n",
    "df_train = df_temp[df_temp.saleYear != 2012].copy()\n",
    "\n",
    "# 2) Imputation-Statistiken nur aus Training\n",
    "num_cols = df_train.select_dtypes(include=\"number\").columns\n",
    "medians = df_train[num_cols].median()\n",
    "\n",
    "df_train[num_cols] = df_train[num_cols].fillna(medians)\n",
    "\n",
    "# 2) Imputation-Statistiken nur aus Validation\n",
    "num_cols = df_val.select_dtypes(include=\"number\").columns\n",
    "medians = df_val[num_cols].median()\n",
    "\n",
    "df_val[num_cols] = df_val[num_cols].fillna(medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y \n",
    "\n",
    "X_train,y_train = df_train.drop(\"SalePrice\",axis = 1), df_train.SalePrice\n",
    "\n",
    "# Split data into X and y \n",
    "\n",
    "X_valid,y_valid = df_val.drop(\"SalePrice\",axis = 1), df_val.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "### Build an evaluation fuction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "<img src=\"./images/metric.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation function (the competition uses RMSLE) \n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error,r2_score\n",
    "\n",
    "def rmsle (y_test,y_preds):\n",
    "    \"\"\"\n",
    "    Calculates root mean squared log error between predictions and true labels. \n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(y_test,y_preds))\n",
    "\n",
    "# Create a function to evaluate model on a few diffrent levels \n",
    "def show_scores(model):\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_valid)\n",
    "    scores = {\"Training MAE\":mean_absolute_error(y_train,train_preds),\n",
    "    \"Valid MAE\": mean_absolute_error(y_valid,val_preds),\n",
    "    \"Training RMSLE\":rmsle(y_train,train_preds),\n",
    "    \"Valid RMSLE\":rmsle(y_valid,val_preds),\n",
    "    \"Training r^2\":r2_score(y_train,train_preds),\n",
    "    \"Valid r^2\":r2_score(y_valid,val_preds)}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "## Testing our model on a subset (to tune the hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_jobs = -1,\n",
    "                              random_state = 42) \n",
    "\n",
    "#This takes far too long .... for experimenting\n",
    "#model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change max_samples value \n",
    "\n",
    "model = RandomForestRegressor(n_jobs = -1, random_state = 42,max_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##cutting down on the max number of samples each estimators can see improves training time\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Diffrent RandomForestRegressor HP \n",
    "rf_grid ={\n",
    "    \"n_estimators\":np.arange(10,100,10),\n",
    "    \"max_depth\":[None,3,5,10],\n",
    "    \"min_samples_split\": np.arange(2,20,2),\n",
    "    \"min_samples_leaf\":np.arange(1,20,2),\n",
    "    \"max_samples\":[10000],\n",
    "    \"max_features\":[0.5,1,\"sqrt\",\"auto\"]\n",
    "}\n",
    "\n",
    "# Instantiate RandomizesSearchCV \n",
    "rs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs = -1, random_state = 42), param_distributions=rf_grid,\n",
    "                              n_iter= 5, # very low because it take too long! \n",
    "                              cv=5, \n",
    "                              verbose = True)\n",
    "\n",
    "#Fit the RSCV model\n",
    "rs_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best HP for the model \n",
    "\n",
    "rs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the randomized Search Model \n",
    "show_scores(rs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "### Train the model with the best hyperparameters \n",
    "\n",
    "**Note** These were found after 100 iterations of RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Most ideal Hyperparameters \n",
    "\n",
    "ideal_model = RandomForestRegressor(n_estimators = 40,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    min_samples_split=14,\n",
    "                                    max_features=0.5,\n",
    "                                    n_jobs = -1,\n",
    "                                    max_samples = None,\n",
    "                                   random_state = 42 # so our results are reproducable\n",
    ")\n",
    "\n",
    "#Fit the ideal model \n",
    "ideal_model.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(ideal_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "## Make Predictions on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the test data \n",
    "\n",
    "df_test = pd.read_csv(\"data/Test.csv\", low_memory = False, parse_dates=[\"saledate\"]) \n",
    "\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "## Preprocessing the data to the same format like X_Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(df):\n",
    "    \"\"\"\n",
    "    Performs transformation on df and returns transformed df. \n",
    "    \"\"\"\n",
    "    df[\"saleYear\"] = df.saledate.dt.year\n",
    "    df[\"saleMonth\"] = df.saledate.dt.month\n",
    "    df[\"saleDay\"] = df.saledate.dt.day\n",
    "    df[\"saleDayOfWeek\"] = df.saledate.dt.dayofweek\n",
    "    df[\"saleDayOfYear\"] = df.saledate.dt.dayofyear\n",
    "\n",
    "    df.drop(\"saledate\", axis = 1, inplace = True)\n",
    "    \n",
    "    # Fill the numeric rows with median \n",
    "    for label,content in df.items():\n",
    "        if pd.api.types.is_numeric_dtype(content):\n",
    "            if pd.isnull(content).sum():\n",
    "            #Add a binary column which tells us if the data was missing \n",
    "                df[label+\"_is_missing\"] = pd.isnull(content) \n",
    "            #Fill missing numeric values with median \n",
    "                df[label]= content.fillna(content.median())\n",
    "\n",
    "    #Filled categorical missing datat and turned categories into numbers \n",
    "\n",
    "        if not pd.api.types.is_numeric_dtype(content):\n",
    "            df[label+\"_is_missing\"] = pd.isnull(content) \n",
    "        #We add +1 to the category code because pandas encodes missing categories with -1 \n",
    "            df[label]=pd.Categorical(content).codes+1\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = preprocessing_data(df_test)\n",
    "\n",
    "df_test.columns, df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on updated Test data dont work because a feature is missing\n",
    "#test_preds = ideal_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find how the columns differ using sets\n",
    "set(X_train.columns)-set(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually fit the column \n",
    "df_test[\"auctioneerID_is_missing\"] = False\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nach model.fit(X_train, y_train)\n",
    "fit_cols = ideal_model.feature_names_in_\n",
    "\n",
    "# X_test / X_new exakt wie beim Fit ausrichten\n",
    "X_new_aligned = df_test.reindex(columns=fit_cols, fill_value=0)\n",
    "\n",
    "\n",
    "\n",
    "test_preds = ideal_model.predict(X_new_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find how the columns differ using sets\n",
    "set(X_train.columns)-set(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format  predictions into the same format Kaggle is after \n",
    "\n",
    "df_preds = pd.DataFrame()\n",
    "df_preds [\"SalesID\"] = df_test[\"SalesID\"]\n",
    "df_preds [\"SalesPrice\"] = test_preds\n",
    "\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_csv(\"data/test_predictions.csv\", index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "seeks to figure out which diffrent attributes of the data were most importance when it comes to predicting the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FInd feature importance of our best models \n",
    "\n",
    "len(ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting feature importance\n",
    "def plot_features(columns, importanceFactor, top_n=20):\n",
    "    columns = np.array(columns)\n",
    "    importanceFactor = np.array(importanceFactor)\n",
    "\n",
    "    # sortiere nach Wichtigkeit (absteigend) und nimm Top-N\n",
    "    idx = np.argsort(importanceFactor)[::-1][:top_n]\n",
    "    cols = columns[idx]\n",
    "    imps = importanceFactor[idx]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.barh(cols[::-1], imps[::-1])  # barh + umdrehen => wichtigste oben\n",
    "    ax.set_xlabel(\"Feature importance\")\n",
    "    ax.set_title(f\"Top {top_n} Feature Importances\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_features(X_new_aligned.columns, ideal_model.feature_importances_, top_n=20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(X_new_aligned.columns,ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_other_way (columns, importances, n = 20):\n",
    "    df = (pd.DataFrame({\"features\":columns, \n",
    "                        \"features_importances\": importances})\n",
    "          .sort_values(\"features_importances\",ascending = False) \n",
    "          .reset_index(drop=True)) \n",
    "\n",
    "    # PLot the dataframe \n",
    "    fig, ax = plt.subplots() \n",
    "    #ax.barh(np.flip(np.array(df[\"features\"][:n:])), np.flip(np.array(df[\"features_importances\"][:n:])))\n",
    "    ax.barh(df[\"features\"][:n:][::-1], df[\"features_importances\"][:n:][::-1])\n",
    "    ax.set_xlabel(\"Feature importance\")\n",
    "    ax.set_title(f\"Top {n} Feature Importances\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_other_way(X_new_aligned.columns,ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "**Question to finish:**  Why might knowing the feature importances of a trained machine learning model be helpful?\n",
    "\n",
    "**Final challenge:** What other machine learning models could you try on our dataset? Hint checkout the regression section of scikit learn map or try to look at CatBoost.ai or XGBoost.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
